{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T19:40:32.505814Z",
     "iopub.status.busy": "2023-07-28T19:40:32.505281Z",
     "iopub.status.idle": "2023-07-28T19:40:32.513115Z",
     "shell.execute_reply": "2023-07-28T19:40:32.511735Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "ROOT = Path(\"../\")\n",
    "DATA = ROOT / \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T19:40:32.516219Z",
     "iopub.status.busy": "2023-07-28T19:40:32.515986Z",
     "iopub.status.idle": "2023-07-28T19:40:35.384798Z",
     "shell.execute_reply": "2023-07-28T19:40:35.384060Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "import cv2\n",
    "from dvclive import Live\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and split it into train/test\n",
    "\n",
    "We have some [data in DVC](https://dvc.org/doc/start/data-management/data-versioning) that we can pull. \n",
    "\n",
    "This data includes:\n",
    "* satellite images\n",
    "* masks of the swimming pools in each satellite image\n",
    "\n",
    "DVC can help connect your data to your repo, but it isn't necessary to have your data in DVC to start tracking experiments with DVC and DVCLive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T19:40:35.389763Z",
     "iopub.status.busy": "2023-07-28T19:40:35.388443Z",
     "iopub.status.idle": "2023-07-28T19:40:36.871542Z",
     "shell.execute_reply": "2023-07-28T19:40:36.869309Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything is up to date.\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc pull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to YOLO Dataset format\n",
    "\n",
    "https://docs.ultralytics.com/datasets/segment/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T19:40:36.875954Z",
     "iopub.status.busy": "2023-07-28T19:40:36.875251Z",
     "iopub.status.idle": "2023-07-28T19:40:36.880690Z",
     "shell.execute_reply": "2023-07-28T19:40:36.879971Z"
    }
   },
   "outputs": [],
   "source": [
    "def mask_to_yolo_annotation(mask):\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    annotation = \"\"\n",
    "    for contour in contours:\n",
    "        single_annotation = \"0\"\n",
    "        for row, col in contour.squeeze():\n",
    "            single_annotation += f\" {round(col / mask.shape[1], 3)} {round(row / mask.shape[0], 3)}\"\n",
    "        annotation += f\"{single_annotation}\\n\"\n",
    "    return annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T19:40:36.883669Z",
     "iopub.status.busy": "2023-07-28T19:40:36.883184Z",
     "iopub.status.idle": "2023-07-28T19:40:38.149551Z",
     "shell.execute_reply": "2023-07-28T19:40:38.148761Z"
    }
   },
   "outputs": [],
   "source": [
    "test_regions = [\"REGION_1-\"]\n",
    "\n",
    "train_data_dir = DATA / \"yolo_dataset\" / \"train\"\n",
    "train_data_dir.mkdir(exist_ok=True, parents=True)\n",
    "test_data_dir = DATA / \"yolo_dataset\" / \"val\"\n",
    "test_data_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "for img_path in DATA.glob(\"pool_data/images/*.jpg\"):\n",
    "    yolo_annotation = mask_to_yolo_annotation(\n",
    "        cv2.imread(\n",
    "            str(DATA / \"pool_data\" / \"masks\" / f\"{img_path.stem}.png\"),\n",
    "            cv2.IMREAD_GRAYSCALE\n",
    "        )\n",
    "    )\n",
    "\n",
    "    if any(region in str(img_path) for region in test_regions):\n",
    "        dst = test_data_dir / img_path.name\n",
    "    else:\n",
    "        dst = train_data_dir / img_path.name\n",
    "\n",
    "    shutil.copy(img_path, dst)\n",
    "    dst.with_suffix(\".txt\").write_text(yolo_annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T19:40:38.153622Z",
     "iopub.status.busy": "2023-07-28T19:40:38.153014Z",
     "iopub.status.idle": "2023-07-28T19:40:38.160953Z",
     "shell.execute_reply": "2023-07-28T19:40:38.160186Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yolo_dataset_yaml = DATA / \"yolo_dataset.yaml\"\n",
    "yolo_dataset_yaml.write_text(\n",
    "    \"\"\"\n",
    "path: ./yolo_dataset\n",
    "train: train\n",
    "val: val\n",
    "\n",
    "names:\n",
    "  0: swimming_pool\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train multiple models with different number of epochs\n",
    "Set up model training, using DVCLive to capture the results of each experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T19:40:38.164097Z",
     "iopub.status.busy": "2023-07-28T19:40:38.163515Z",
     "iopub.status.idle": "2023-07-28T19:40:38.172422Z",
     "shell.execute_reply": "2023-07-28T19:40:38.171754Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_callbacks(live, yolo):\n",
    "    def _log_confusion_matrix(validator, live):\n",
    "        targets = []\n",
    "        preds = []\n",
    "        matrix = validator.confusion_matrix.matrix\n",
    "        names = list(validator.names.values())\n",
    "        if validator.confusion_matrix.task == \"detect\":\n",
    "            names += [\"background\"]\n",
    "\n",
    "        for ti, pred in enumerate(matrix.T.astype(int)):\n",
    "            for pi, num in enumerate(pred):\n",
    "                targets.extend([names[ti]] * num)\n",
    "                preds.extend([names[pi]] * num)\n",
    "\n",
    "        live.log_sklearn_plot(\"confusion_matrix\", targets, preds)\n",
    "\n",
    "    def on_train_epoch_start(trainer):\n",
    "        trainer.__training_epoch = True\n",
    "\n",
    "    def on_fit_epoch_end(trainer):\n",
    "        if trainer.__training_epoch:\n",
    "            all_metrics = {\n",
    "                **trainer.label_loss_items(trainer.tloss, prefix=\"train\"),\n",
    "                **trainer.metrics,\n",
    "            }\n",
    "            for metric, value in all_metrics.items():\n",
    "                live.log_metric(metric, value)\n",
    "\n",
    "            live.next_step()\n",
    "            trainer.__training_epoch = False\n",
    "\n",
    "    def on_train_end(trainer):\n",
    "        all_metrics = {\n",
    "            **trainer.label_loss_items(trainer.tloss, prefix=\"train\"),\n",
    "            **trainer.metrics,\n",
    "        }\n",
    "        for metric, value in all_metrics.items():\n",
    "            live.log_metric(metric, value, plot=False)\n",
    "\n",
    "        _log_confusion_matrix(trainer.validator, live)\n",
    "\n",
    "        for image_path in trainer.validator.plots.keys():\n",
    "            if \"val_batch\" in image_path.name:\n",
    "                live.log_image(image_path.name, image_path)\n",
    "\n",
    "        if trainer.best.exists():\n",
    "            live.log_artifact(\n",
    "                trainer.best, name=\"pool-segmentation\", type=\"model\", copy=True,\n",
    "                desc=\"This is a Computer Vision (CV) model that's segmenting out swimming pools from satellite images.\",\n",
    "                labels=[\"cv\", \"segmentation\", \"satellite-images\", \"yolo\"],\n",
    "            )\n",
    "\n",
    "    yolo.callbacks[\"on_train_epoch_start\"].append(on_train_epoch_start)\n",
    "    yolo.callbacks[\"on_fit_epoch_end\"].append(on_fit_epoch_end)\n",
    "    yolo.callbacks[\"on_train_end\"].append(on_train_end)\n",
    "\n",
    "    return yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T19:40:38.175293Z",
     "iopub.status.busy": "2023-07-28T19:40:38.174859Z",
     "iopub.status.idle": "2023-07-28T19:41:40.082004Z",
     "shell.execute_reply": "2023-07-28T19:41:40.081106Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n-seg.pt to 'yolov8n-seg.pt'...\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.73M/6.73M [00:00<00:00, 64.1MB/s]\n",
      "Ultralytics YOLOv8.0.143 ðŸš€ Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla V100-PCIE-16GB, 16151MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=yolov8n-seg.pt, data=/workspaces/example-repos-dev/example-get-started-experiments/build/example-get-started-experiments/data/yolo_dataset.yaml, epochs=20, patience=50, batch=16, imgsz=384, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=/workspaces/example-repos-dev/example-get-started-experiments/build/example-get-started-experiments/runs/segment/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1   1004275  ultralytics.nn.modules.head.Segment          [1, 32, 64, [64, 128, 256]]   \n",
      "YOLOv8n-seg summary: 261 layers, 3263811 parameters, 3263795 gradients\n",
      "\n",
      "Transferred 381/417 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to 'yolov8n.pt'...\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.23M/6.23M [00:00<00:00, 21.6MB/s]\n",
      "/workspaces/example-repos-dev/example-get-started-experiments/build/example-get-started-experiments/.venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:459: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "train: Scanning /workspaces/example-repos-dev/example-get-started-experiments/build/example-get-started-experiments/data/yolo_dataset/train... 79 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:00<00:00, 9\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /workspaces/example-repos-dev/example-get-started-experiments/build/example-get-started-experiments/data/yolo_dataset/train.cache\n",
      "val: Scanning /workspaces/example-repos-dev/example-get-started-experiments/build/example-get-started-experiments/data/yolo_dataset/val... 12 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:00<00:00, 441.9\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /workspaces/example-repos-dev/example-get-started-experiments/build/example-get-started-experiments/data/yolo_dataset/val.cache\n",
      "Plotting labels to /workspaces/example-repos-dev/example-get-started-experiments/build/example-get-started-experiments/runs/segment/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n",
      "Image sizes 384 train, 384 val\n",
      "Using 6 dataloader workers\n",
      "Logging results to \u001b[1m/workspaces/example-repos-dev/example-get-started-experiments/build/example-get-started-experiments/runs/segment/train\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/20      1.43G      4.454      5.954      4.362      2.665        132        384: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:03<00:00,  1.57it/s]\n",
      "/workspaces/example-repos-dev/example-get-started-experiments/build/example-get-started-experiments/.venv/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.32it/s]\n",
      "                   all         12         46   0.000278     0.0217   0.000143   2.86e-05          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/20      1.46G      4.435      5.867      4.235       2.68        125        384: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  6.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.59it/s]\n",
      "                   all         12         46   0.000278     0.0217   0.000143   2.86e-05          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/20      1.48G      4.154      5.095      4.184      2.466        133        384: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  6.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.56it/s]\n",
      "                   all         12         46   0.000278     0.0217   0.000143   2.86e-05          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/20      1.49G      3.931      4.962      4.037      2.304         91        384: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  7.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.52it/s]\n",
      "                   all         12         46   0.000278     0.0217   0.000143   2.86e-05          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/20      1.48G      3.969      4.925      4.011      2.195        140        384: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  7.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.46it/s]\n",
      "                   all         12         46   0.000278     0.0217    0.00015    1.5e-05          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/20      1.48G      3.851      4.783      3.869      2.102        107        384: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  8.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.63it/s]\n",
      "                   all         12         46   0.000833     0.0652   0.000461   0.000123          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/20      1.49G      3.814      4.757      3.878      2.015        128        384: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  8.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.43it/s]\n",
      "                   all         12         46    0.00111      0.087   0.000621   0.000107          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/20       1.5G      3.667      4.695      3.797      1.904        144        384: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  8.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.89it/s]\n",
      "                   all         12         46   0.000833     0.0652    0.00047   7.74e-05   0.000556     0.0435   0.000295   2.95e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/20      1.48G      3.681      4.712       3.72      1.818        154        384: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  7.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.48it/s]\n",
      "                   all         12         46   0.000833     0.0652    0.00047   7.74e-05   0.000556     0.0435   0.000295   2.95e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/20      1.49G      3.651      4.752      3.663      1.841        121        384: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  7.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.51it/s]\n",
      "                   all         12         46   0.000278     0.0217   0.000143   5.71e-05   0.000556     0.0435   0.000292   4.34e-05\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      11/20       1.5G      3.653      4.793      3.764      1.858         78        384: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:02<00:00,  2.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.93it/s]\n",
      "                   all         12         46   0.000278     0.0217   0.000144   1.44e-05   0.000278     0.0217   0.000144   4.33e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      12/20       1.5G      3.636      4.816      3.745      1.832         89        384: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  8.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.79it/s]\n",
      "                   all         12         46    0.00139      0.109   0.000791    0.00017    0.00111      0.087   0.000618   0.000137\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      13/20      1.49G      3.508       4.77      3.735      1.856         72        384: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  8.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.86it/s]\n",
      "                   all         12         46    0.00194      0.152    0.00125    0.00022    0.00167       0.13    0.00104   0.000254\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      14/20      1.48G      3.464      4.615      3.691      1.827         75        384: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  8.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.04it/s]\n",
      "                   all         12         46    0.00167       0.13   0.000969   0.000216   0.000833     0.0652    0.00045   0.000133\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      15/20      1.48G      3.593      4.604      3.695      1.865         70        384: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  8.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.20it/s]\n",
      "                   all         12         46    0.00111      0.087   0.000661   0.000142   0.000278     0.0217   0.000146   8.78e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      16/20      1.49G      3.469      4.663      3.624      1.777         70        384: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  8.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.00it/s]\n",
      "                   all         12         46    0.00167       0.13     0.0011   0.000257   0.000278     0.0217   0.000145   8.71e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      17/20      1.48G      3.501      4.673      3.632      1.817         70        384: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  8.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.85it/s]\n",
      "                   all         12         46    0.00167       0.13    0.00107   0.000184    0.00139      0.109   0.000811   0.000207\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      18/20      1.49G      3.465      4.685      3.664       1.77         73        384: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  8.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.05it/s]\n",
      "                   all         12         46    0.00194      0.152    0.00124   0.000168    0.00167       0.13    0.00101   0.000229\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      19/20      1.48G      3.395      4.671      3.602      1.739         76        384: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  8.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.05it/s]\n",
      "                   all         12         46    0.00111      0.087   0.000708   0.000132   0.000556     0.0435     0.0003   7.46e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      20/20      1.48G      3.547      4.738      3.657      1.764         66        384: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  8.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.53it/s]\n",
      "                   all         12         46    0.00222      0.174    0.00145   0.000276    0.00139      0.109   0.000813   0.000235\n",
      "\n",
      "20 epochs completed in 0.012 hours.\n",
      "Optimizer stripped from /workspaces/example-repos-dev/example-get-started-experiments/build/example-get-started-experiments/runs/segment/train/weights/last.pt, 6.7MB\n",
      "Optimizer stripped from /workspaces/example-repos-dev/example-get-started-experiments/build/example-get-started-experiments/runs/segment/train/weights/best.pt, 6.7MB\n",
      "\n",
      "Validating /workspaces/example-repos-dev/example-get-started-experiments/build/example-get-started-experiments/runs/segment/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.143 ðŸš€ Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla V100-PCIE-16GB, 16151MiB)\n",
      "YOLOv8n-seg summary (fused): 195 layers, 3258259 parameters, 0 gradients\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  6.43it/s]\n",
      "                   all         12         46    0.00222      0.174    0.00145   0.000292    0.00139      0.109   0.000813   0.000235\n",
      "Speed: 0.1ms preprocess, 0.9ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Results saved to \u001b[1m/workspaces/example-repos-dev/example-get-started-experiments/build/example-get-started-experiments/runs/segment/train\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: The following untracked files were present in the workspace before saving but will not be included in the experiment commit:\n",
      "\truns/segment/train/BoxP_curve.png, runs/segment/train/BoxR_curve.png, runs/segment/train/confusion_matrix.png, runs/segment/train/results.csv, runs/segment/train/args.yaml, runs/segment/train/MaskP_curve.png, runs/segment/train/val_batch0_labels.jpg, runs/segment/train/labels_correlogram.jpg, runs/segment/train/train_batch0.jpg, runs/segment/train/MaskPR_curve.png, runs/segment/train/BoxPR_curve.png, runs/segment/train/MaskF1_curve.png, runs/segment/train/train_batch52.jpg, runs/segment/train/labels.jpg, runs/segment/train/BoxF1_curve.png, runs/segment/train/train_batch50.jpg, runs/segment/train/train_batch2.jpg, runs/segment/train/MaskR_curve.png, runs/segment/train/train_batch51.jpg, runs/segment/train/results.png, runs/segment/train/val_batch0_pred.jpg, runs/segment/train/confusion_matrix_normalized.png, runs/segment/train/train_batch1.jpg, runs/segment/train/weights/last.pt, runs/segment/train/weights/best.pt, data/yolo_dataset.yaml, notebooks/yolov8n-seg.pt, notebooks/yolov8n.pt\n"
     ]
    }
   ],
   "source": [
    "imgsz = 384\n",
    "epochs = 20\n",
    "model = \"yolov8n-seg.pt\"\n",
    "results_dir = ROOT / \"results\" / \"train\"\n",
    "\n",
    "yolo = YOLO(model)\n",
    "\n",
    "with Live(str(results_dir), save_dvc_exp=True, report=None, cache_images=True) as live:\n",
    "    live.log_params({\n",
    "        \"epochs\": epochs,\n",
    "        \"imgsz\": imgsz,\n",
    "        \"model\": model\n",
    "    })\n",
    "    yolo = add_callbacks(live, yolo)\n",
    "    yolo.train(data=(DATA / \"yolo_dataset.yaml\").resolve(), epochs=epochs, imgsz=imgsz)\n",
    "\n",
    "try:\n",
    "    os.remove(DATA / \"yolo_dataset\" / \"train.cache\")\n",
    "    os.remove(DATA / \"yolo_dataset\" / \"val.cache\")\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "\n",
    "shutil.rmtree(\"../runs\", ignore_errors=True)\n",
    "shutil.rmtree(\"../weights\", ignore_errors=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
